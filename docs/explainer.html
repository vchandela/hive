<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hive ‚Äî Retrieval Engine with Verifiable Feedback Loops</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
    <script>
        tailwind.config = {
            theme: {
                extend: {
                    colors: {
                        dark: '#0f172a',
                        card: '#1e293b',
                        border: '#334155',
                    }
                }
            }
        }
    </script>
    <style>
        @keyframes fill-bar {
            0% { width: 35%; background: #ef4444; }
            50% { width: 58%; background: #eab308; }
            100% { width: 75%; background: #22c55e; }
        }
        .animate-fill { animation: fill-bar 3s ease-in-out forwards; }
        .card-expand { transition: max-height 0.3s ease, opacity 0.3s ease; max-height: 0; opacity: 0; overflow: hidden; }
        .card-expand.open { max-height: 500px; opacity: 1; }
    </style>
</head>
<body class="bg-dark text-gray-200 font-sans">

<!-- Hero: The Problem -->
<section class="min-h-screen flex flex-col justify-center px-6 py-20 max-w-5xl mx-auto">
    <h1 class="text-4xl md:text-5xl font-bold text-white mb-6">
        Your AI Agent Is Being Sabotaged<br>by Its Own Search Results
    </h1>
    <p class="text-lg text-gray-400 mb-12 max-w-2xl">
        When an LLM retrieves context, a result that <em>looks right but is wrong</em> doesn't just waste a slot ‚Äî it actively corrupts reasoning. Traditional metrics can't see this. Hive can.
    </p>

    <!-- Search results visualization -->
    <div class="space-y-3 mb-12 max-w-xl">
        <div class="flex items-center gap-3 bg-green-900/30 border border-green-700/50 rounded-lg px-4 py-3">
            <span class="text-green-400 font-mono text-sm w-6">#1</span>
            <span class="flex-1">API Authentication: Bearer Tokens & API Keys</span>
            <span class="text-green-400 text-xs font-semibold px-2 py-0.5 bg-green-900/50 rounded">RELEVANT</span>
        </div>
        <div class="flex items-center gap-3 bg-red-900/30 border border-red-700/50 rounded-lg px-4 py-3">
            <span class="text-red-400 font-mono text-sm w-6">#2</span>
            <span class="flex-1">Authentication FAQ: Password Reset & 2FA Setup</span>
            <span class="text-red-400 text-xs font-semibold px-2 py-0.5 bg-red-900/50 rounded flex items-center gap-1">
                <svg class="w-3 h-3" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 9v2m0 4h.01M21 12a9 9 0 11-18 0 9 9 0 0118 0z"/></svg>
                DISTRACTOR
            </span>
        </div>
        <div class="flex items-center gap-3 bg-green-900/30 border border-green-700/50 rounded-lg px-4 py-3">
            <span class="text-green-400 font-mono text-sm w-6">#3</span>
            <span class="flex-1">API Authentication: Token Refresh</span>
            <span class="text-green-400 text-xs font-semibold px-2 py-0.5 bg-green-900/50 rounded">RELEVANT</span>
        </div>
        <div class="flex items-center gap-3 bg-gray-800 border border-gray-700/50 rounded-lg px-4 py-3">
            <span class="text-gray-500 font-mono text-sm w-6">#4</span>
            <span class="flex-1 text-gray-500">Rate Limits: Handling 429 Errors</span>
            <span class="text-gray-500 text-xs px-2 py-0.5 bg-gray-800 rounded">IRRELEVANT</span>
        </div>
        <div class="flex items-center gap-3 bg-green-900/30 border border-green-700/50 rounded-lg px-4 py-3">
            <span class="text-green-400 font-mono text-sm w-6">#5</span>
            <span class="flex-1">SDK Authentication Configuration</span>
            <span class="text-green-400 text-xs font-semibold px-2 py-0.5 bg-green-900/50 rounded">RELEVANT</span>
        </div>
    </div>

    <div class="bg-card border border-border rounded-lg p-4 mb-8 max-w-xl">
        <p class="text-gray-400 text-sm">
            The red card shares keywords with the query ("authentication") but answers a completely different question (password resets, not API tokens). When the LLM reads it, it contaminates the answer. This is <strong class="text-white">Mutually Assured Distraction (MAD)</strong>.
        </p>
    </div>

    <!-- nDCG vs nUDCG -->
    <div class="flex flex-col md:flex-row gap-4 max-w-xl">
        <div class="flex-1 bg-green-900/20 border border-green-700/40 rounded-lg p-6 text-center">
            <div class="text-sm text-green-400 font-semibold mb-1">nDCG says</div>
            <div class="text-3xl font-bold text-green-400">0.75</div>
            <div class="text-xs text-green-400/60 mt-1">"Looks fine"</div>
        </div>
        <div class="flex-1 bg-amber-900/20 border border-amber-700/40 rounded-lg p-6 text-center">
            <div class="text-sm text-amber-400 font-semibold mb-1">nUDCG says</div>
            <div class="text-3xl font-bold text-amber-400">0.35</div>
            <div class="text-xs text-amber-400/60 mt-1">"Reveals the problem"</div>
        </div>
    </div>
</section>

<!-- The Feedback Loop -->
<section class="px-6 py-20 max-w-5xl mx-auto">
    <h2 class="text-3xl font-bold text-white mb-4">The Feedback Loop</h2>
    <p class="text-gray-400 mb-10 max-w-2xl">The agent writes configs, measures results, and iterates ‚Äî like a developer running tests after each code change.</p>

    <div class="flex flex-col md:flex-row gap-4 mb-10">
        <div class="flex-1 bg-card border border-border rounded-lg p-5 cursor-pointer" onclick="toggleDetail('d1')">
            <div class="flex items-center gap-3 mb-2">
                <span class="text-2xl">üìù</span>
                <span class="font-semibold text-white">1. Config</span>
            </div>
            <p class="text-sm text-gray-400">Agent writes a JSON config controlling search behavior</p>
            <div id="d1" class="card-expand mt-3 text-xs text-gray-500">
                The config specifies: method (keyword, vector, hybrid), how many results, what filters to apply, whether to enable dynamic-k and distraction detection. It's a file on disk ‚Äî versioned, diffable, reviewable.
            </div>
        </div>
        <div class="flex-1 bg-card border border-border rounded-lg p-5 cursor-pointer" onclick="toggleDetail('d2')">
            <div class="flex items-center gap-3 mb-2">
                <span class="text-2xl">üîç</span>
                <span class="font-semibold text-white">2. Search</span>
            </div>
            <p class="text-sm text-gray-400">Hive runs the search with ranked results and scores</p>
            <div id="d2" class="card-expand mt-3 text-xs text-gray-500">
                Combines BM25 (keyword) and vector (semantic) search via Reciprocal Rank Fusion. Optionally flags results where the two methods disagree ‚Äî a signal of potential distractors.
            </div>
        </div>
        <div class="flex-1 bg-card border border-border rounded-lg p-5 cursor-pointer" onclick="toggleDetail('d3')">
            <div class="flex items-center gap-3 mb-2">
                <span class="text-2xl">üìä</span>
                <span class="font-semibold text-white">3. Evaluate</span>
            </div>
            <p class="text-sm text-gray-400">Scores results against known-good answers using UDCG</p>
            <div id="d3" class="card-expand mt-3 text-xs text-gray-500">
                UDCG assigns +1 to relevant results, -1 to distractors, and 0 to irrelevant ones. Each is weighted by rank position ‚Äî top ranks matter most. The resulting score reveals problems that nDCG hides.
            </div>
        </div>
        <div class="flex-1 bg-card border border-border rounded-lg p-5 cursor-pointer" onclick="toggleDetail('d4')">
            <div class="flex items-center gap-3 mb-2">
                <span class="text-2xl">üß†</span>
                <span class="font-semibold text-white">4. Reason</span>
            </div>
            <p class="text-sm text-gray-400">Agent reads scores and identifies what went wrong</p>
            <div id="d4" class="card-expand mt-3 text-xs text-gray-500">
                The LLM sees: "nUDCG is 0.38, 2 distractors from FAQs." It reasons: "FAQ documents share keywords with API docs but answer different questions. I should filter them out or enable distraction detection."
            </div>
        </div>
        <div class="flex-1 bg-card border border-border rounded-lg p-5 cursor-pointer" onclick="toggleDetail('d5')">
            <div class="flex items-center gap-3 mb-2">
                <span class="text-2xl">üîß</span>
                <span class="font-semibold text-white">5. Improve</span>
            </div>
            <p class="text-sm text-gray-400">Agent writes a new config and the loop repeats</p>
            <div id="d5" class="card-expand mt-3 text-xs text-gray-500">
                The new config might enable category filtering, turn on dynamic-k, or adjust disagreement thresholds. It's validated before evaluation ‚Äî just like compiling code before running tests.
            </div>
        </div>
    </div>

    <!-- Progress bar -->
    <div class="max-w-xl">
        <div class="flex justify-between text-sm text-gray-400 mb-2">
            <span>nUDCG Progress</span>
            <span>0.35 ‚Üí 0.58 ‚Üí 0.75</span>
        </div>
        <div class="w-full bg-gray-800 rounded-full h-4 overflow-hidden" id="progress-bar-container">
            <div class="h-full rounded-full animate-fill" style="width: 35%"></div>
        </div>
    </div>
</section>

<!-- First Principles & Primitives -->
<section class="px-6 py-20 max-w-5xl mx-auto">
    <h2 class="text-3xl font-bold text-white mb-4">First Principles & Primitives</h2>
    <p class="text-gray-400 mb-12 max-w-3xl">
        Hive is built on a small set of composable primitives. Each one solves a specific problem in retrieval quality ‚Äî and together they form a system where an AI agent can self-improve without human intervention. These aren't abstract ideas; each primitive maps to concrete code and measurable behavior.
    </p>

    <!-- Primitive 1: Everything is a file -->
    <div class="mb-10">
        <div class="flex items-start gap-4 mb-4">
            <span class="flex-shrink-0 w-10 h-10 rounded-full bg-blue-900/50 flex items-center justify-center text-blue-400 font-bold text-sm mt-1">1</span>
            <div>
                <h3 class="text-xl font-semibold text-white mb-1">Everything Is a File</h3>
                <p class="text-gray-400 text-sm">The agent's interface is a directory of JSON files ‚Äî no custom protocols, no APIs to learn.</p>
            </div>
        </div>
        <div class="bg-card border border-border rounded-lg p-6 ml-14">
            <p class="text-sm text-gray-400 mb-4">
                This is the key Hornet insight: <strong class="text-gray-200">align retrieval configuration with how coding agents already work.</strong> An agent that can edit <code class="text-blue-400">tsconfig.json</code> can edit a Hive config. No new abstractions. The entire workspace is files on disk ‚Äî versioned, diffable, reviewable.
            </p>
            <div class="bg-gray-900/60 rounded-lg p-4 font-mono text-sm text-gray-400 mb-4">
                <div>workspace/</div>
                <div class="ml-4">collections/knowledge-base.json <span class="text-gray-600">‚Äî "what does the data look like?"</span></div>
                <div class="ml-4">configs/v1.json <span class="text-gray-600">‚Äî "how should I search?" (the code)</span></div>
                <div class="ml-4">configs/v2.json <span class="text-gray-600">‚Äî "improved version" (agent creates this)</span></div>
                <div class="ml-4">configs/active.json <span class="text-gray-600">‚Äî symlink to deployed config</span></div>
                <div class="ml-4">documents/*.md <span class="text-gray-600">‚Äî the actual content</span></div>
                <div class="ml-4">evals/golden.json <span class="text-gray-600">‚Äî known-good query-result pairs</span></div>
            </div>
            <p class="text-xs text-gray-500">
                Why this matters: LLM agents are fundamentally code-writing tools. They understand files, directories, and JSON. By making retrieval config a file, we turn search optimization into a coding task ‚Äî which is exactly what these agents are good at.
            </p>
        </div>
    </div>

    <!-- Primitive 2: Config IS source code -->
    <div class="mb-10">
        <div class="flex items-start gap-4 mb-4">
            <span class="flex-shrink-0 w-10 h-10 rounded-full bg-purple-900/50 flex items-center justify-center text-purple-400 font-bold text-sm mt-1">2</span>
            <div>
                <h3 class="text-xl font-semibold text-white mb-1">The Retrieval Config IS the Source Code</h3>
                <p class="text-gray-400 text-sm">A config file is the "program" that tells Hive how to search. It's the thing the agent iterates on.</p>
            </div>
        </div>
        <div class="bg-card border border-border rounded-lg p-6 ml-14">
            <div class="bg-gray-900/60 rounded-lg p-4 font-mono text-xs text-gray-400 mb-4 overflow-x-auto">
                <pre>{
  "name": "v1-naive",
  "collection": "knowledge-base",
  "retrieval": {
    "method": "hybrid",   <span class="text-gray-600">// keyword | vector | hybrid</span>
    "top_k": 10,
    "rrf_k": 60           <span class="text-gray-600">// RRF constant (see Primitive 6)</span>
  },
  "dynamic_k": {
    "enabled": false,
    "gap_threshold_factor": 3.0,  <span class="text-gray-600">// cliff detection sensitivity</span>
    "min_results": 1,
    "max_results": 10
  },
  "filters": {},           <span class="text-gray-600">// category pre-filtering</span>
  "distraction_detection": {
    "enabled": false,
    "disagreement_threshold": 0.5
  }
}</pre>
            </div>
            <div class="space-y-2 text-sm text-gray-400">
                <p><strong class="text-gray-300">Key design choices in this config:</strong></p>
                <ul class="list-disc ml-5 space-y-1 text-xs">
                    <li><strong class="text-gray-300">RRF instead of weighted scores</strong> ‚Äî scale-invariant, no normalization needed</li>
                    <li><strong class="text-gray-300">gap_threshold_factor</strong> ‚Äî gap-based cliff detection that works with RRF's compressed score range</li>
                    <li><strong class="text-gray-300">distraction_detection requires method: hybrid</strong> ‚Äî needs both BM25 and vector ranks to compute disagreement</li>
                    <li><strong class="text-gray-300">filters</strong> ‚Äî pre-filter by category BEFORE scoring, not after (eliminates distractors before they enter the ranking)</li>
                </ul>
            </div>
        </div>
    </div>

    <!-- Primitive 3: Collection schema -->
    <div class="mb-10">
        <div class="flex items-start gap-4 mb-4">
            <span class="flex-shrink-0 w-10 h-10 rounded-full bg-teal-900/50 flex items-center justify-center text-teal-400 font-bold text-sm mt-1">3</span>
            <div>
                <h3 class="text-xl font-semibold text-white mb-1">Collection Schema Defines Filterable Fields</h3>
                <p class="text-gray-400 text-sm">The agent discovers what data looks like by reading the schema ‚Äî then uses that knowledge to build better configs.</p>
            </div>
        </div>
        <div class="bg-card border border-border rounded-lg p-6 ml-14">
            <p class="text-sm text-gray-400 mb-4">
                Fields marked <code class="text-teal-400">filterable: true</code> can be used in config filters. Filters are applied as a WHERE clause <strong class="text-gray-200">before</strong> scoring (pre-filter), not after. This means distractors in excluded categories never even enter the ranking pipeline.
            </p>
            <div class="bg-gray-900/60 rounded-lg p-4 font-mono text-xs text-gray-400 mb-4 overflow-x-auto">
                <pre>{
  "name": "knowledge-base",
  "fields": {
    "title":    { "type": "text" },
    "category": { "type": "keyword", "filterable": true },
    "content":  { "type": "text" }
  },
  "chunking": {
    "strategy": "by_heading",
    "max_tokens": 512,
    "heading_level": 2
  }
}</pre>
            </div>
            <p class="text-xs text-gray-500">
                The agent can read this file to discover: "category is filterable, and the available values are api-docs, tutorials, faqs, changelogs." Then it can write a config with <code class="text-teal-400">"filters": {"category": ["api-docs", "tutorials"]}</code> to exclude FAQ distractors entirely.
            </p>
        </div>
    </div>

    <!-- Primitive 4: Verifiable APIs / Three-level validation -->
    <div class="mb-10">
        <div class="flex items-start gap-4 mb-4">
            <span class="flex-shrink-0 w-10 h-10 rounded-full bg-green-900/50 flex items-center justify-center text-green-400 font-bold text-sm mt-1">4</span>
            <div>
                <h3 class="text-xl font-semibold text-white mb-1">Verifiable APIs: Three-Level Validation as a Compiler</h3>
                <p class="text-gray-400 text-sm">Every config change goes through syntactic, semantic, and behavioral verification ‚Äî like compiling, linting, and running tests.</p>
            </div>
        </div>
        <div class="bg-card border border-border rounded-lg p-6 ml-14">
            <p class="text-sm text-gray-400 mb-5">
                This is the <strong class="text-gray-200">Verifiable APIs</strong> principle from Hornet: the system's interface should be checkable at multiple levels before anything gets deployed. The agent gets immediate, actionable feedback ‚Äî not vague errors, but specific "here's what's wrong and how to fix it" messages.
            </p>
            <div class="space-y-3 mb-4">
                <div class="bg-blue-900/20 border border-blue-900/30 rounded-lg px-4 py-3">
                    <div class="flex items-center gap-2 mb-1">
                        <span class="text-blue-400 font-semibold text-sm">Level 1: Syntactic</span>
                        <span class="text-xs text-gray-600 ml-auto">Like a compiler</span>
                    </div>
                    <p class="text-xs text-gray-400 mb-2">"Does the config parse correctly?"</p>
                    <div class="bg-gray-900/50 rounded px-3 py-2 text-xs font-mono text-gray-500">
                        Is top_k a positive integer? Is method one of keyword|vector|hybrid? Are all required fields present?
                    </div>
                </div>
                <div class="bg-purple-900/20 border border-purple-900/30 rounded-lg px-4 py-3">
                    <div class="flex items-center gap-2 mb-1">
                        <span class="text-purple-400 font-semibold text-sm">Level 2: Semantic</span>
                        <span class="text-xs text-gray-600 ml-auto">Like a linter</span>
                    </div>
                    <p class="text-xs text-gray-400 mb-2">"Do the settings make logical sense together?"</p>
                    <div class="bg-red-900/20 border border-red-900/30 rounded px-3 py-2 text-xs font-mono text-red-400">
                        ‚úó distraction_detection.enabled is true but method is "keyword".<br>
                        &nbsp;&nbsp;Distraction detection requires hybrid to compare keyword vs vector rankings.<br>
                        &nbsp;&nbsp;‚Üí Set method to "hybrid" or disable distraction detection.
                    </div>
                </div>
                <div class="bg-green-900/20 border border-green-900/30 rounded-lg px-4 py-3">
                    <div class="flex items-center gap-2 mb-1">
                        <span class="text-green-400 font-semibold text-sm">Level 3: Behavioral (Deploy Gate)</span>
                        <span class="text-xs text-gray-600 ml-auto">Like a test suite</span>
                    </div>
                    <p class="text-xs text-gray-400 mb-2">"Does it actually perform better than what's deployed?"</p>
                    <div class="bg-red-900/20 border border-red-900/30 rounded px-3 py-2 text-xs font-mono text-red-400">
                        Deploy BLOCKED: nUDCG regression 0.61 ‚Üí 0.34. The system refuses to make things worse.<br>
                        Run <code>hive compare</code> to see what changed.
                    </div>
                </div>
            </div>
            <p class="text-xs text-gray-500">
                The behavioral gate is the critical innovation: even if a config passes syntactic and semantic checks, it must <strong class="text-gray-400">prove it's better</strong> by running against the golden evaluation set. This prevents an agent from "improving" a config that actually makes retrieval worse.
            </p>
        </div>
    </div>

    <!-- Primitive 5: Dynamic-k -->
    <div class="mb-10">
        <div class="flex items-start gap-4 mb-4">
            <span class="flex-shrink-0 w-10 h-10 rounded-full bg-amber-900/50 flex items-center justify-center text-amber-400 font-bold text-sm mt-1">5</span>
            <div>
                <h3 class="text-xl font-semibold text-white mb-1">Dynamic-k: Gap-Based Cutoff</h3>
                <p class="text-gray-400 text-sm">Instead of always returning top_k results, stop when there's a quality cliff ‚Äî "retrieve less, retrieve better."</p>
            </div>
        </div>
        <div class="bg-card border border-border rounded-lg p-6 ml-14">
            <p class="text-sm text-gray-400 mb-4">
                Traditional retrieval always returns a fixed number of results (e.g., 10). But what if only 5 are good and the rest are noise? Dynamic-k detects the "quality cliff" where results transition from strong to weak, and stops there.
            </p>
            <p class="text-sm text-gray-400 mb-4">
                <strong class="text-gray-200">Why not score-ratio cutoff?</strong> RRF scores are compressed into a narrow band (all values between ~0.018 and ~0.033 for k=60). A result at BM25 rank 20 / vector rank 30 still has a ratio of ~0.72 to the best result. Score-ratio cutoffs would almost never trigger with RRF. Instead, we measure <strong class="text-gray-200">relative gaps</strong>.
            </p>
            <p class="text-sm text-gray-400 mb-4">
                <strong class="text-gray-200">The algorithm:</strong> After ranking by RRF, compute the gap between each consecutive pair. Track a running mean of gaps seen so far. If <code class="text-amber-400">gap_i &gt; gap_threshold_factor &times; mean_gap_so_far</code>, stop ‚Äî cliff detected.
            </p>

            <!-- Worked example table -->
            <div class="overflow-x-auto mb-4">
                <table class="w-full text-xs">
                    <thead>
                        <tr class="text-gray-500 border-b border-border">
                            <th class="text-left py-2 px-3">Rank</th>
                            <th class="text-left py-2 px-3">RRF Score</th>
                            <th class="text-left py-2 px-3">Gap</th>
                            <th class="text-left py-2 px-3">Running Mean</th>
                            <th class="text-left py-2 px-3">Gap / Mean</th>
                        </tr>
                    </thead>
                    <tbody class="text-gray-400 font-mono">
                        <tr class="border-b border-border/50"><td class="py-1.5 px-3">1</td><td class="py-1.5 px-3">0.0328</td><td class="py-1.5 px-3 text-gray-600">‚Äî</td><td class="py-1.5 px-3 text-gray-600">‚Äî</td><td class="py-1.5 px-3 text-gray-600">‚Äî</td></tr>
                        <tr class="border-b border-border/50"><td class="py-1.5 px-3">2</td><td class="py-1.5 px-3">0.0318</td><td class="py-1.5 px-3">0.0010</td><td class="py-1.5 px-3">0.0010</td><td class="py-1.5 px-3 text-green-400">1.0x ‚úì</td></tr>
                        <tr class="border-b border-border/50"><td class="py-1.5 px-3">3</td><td class="py-1.5 px-3">0.0307</td><td class="py-1.5 px-3">0.0011</td><td class="py-1.5 px-3">0.00105</td><td class="py-1.5 px-3 text-green-400">1.0x ‚úì</td></tr>
                        <tr class="border-b border-border/50"><td class="py-1.5 px-3">4</td><td class="py-1.5 px-3">0.0295</td><td class="py-1.5 px-3">0.0012</td><td class="py-1.5 px-3">0.0011</td><td class="py-1.5 px-3 text-green-400">1.1x ‚úì</td></tr>
                        <tr class="border-b border-border/50"><td class="py-1.5 px-3">5</td><td class="py-1.5 px-3">0.0281</td><td class="py-1.5 px-3">0.0014</td><td class="py-1.5 px-3">0.00118</td><td class="py-1.5 px-3 text-green-400">1.2x ‚úì</td></tr>
                        <tr class="border-b border-border/50"><td class="py-1.5 px-3">6</td><td class="py-1.5 px-3">0.0266</td><td class="py-1.5 px-3">0.0015</td><td class="py-1.5 px-3">0.00124</td><td class="py-1.5 px-3 text-green-400">1.2x ‚úì</td></tr>
                        <tr class="bg-red-900/10"><td class="py-1.5 px-3">7</td><td class="py-1.5 px-3">0.0198</td><td class="py-1.5 px-3 text-red-400">0.0068</td><td class="py-1.5 px-3">0.00124</td><td class="py-1.5 px-3 text-red-400 font-bold">5.5x STOP</td></tr>
                    </tbody>
                </table>
            </div>
            <p class="text-xs text-gray-500">
                Returns 6 results instead of 10. Ranks 1‚Äì6 have gradually increasing but consistent gaps (~0.001), then rank 7 drops sharply ‚Äî the cliff. This is interpretable: "stop when the next result is dramatically worse than the trend so far." The approach works with compressed RRF scores because it measures relative gaps, not absolute score levels.
            </p>
        </div>
    </div>

    <!-- Primitive 6: RRF -->
    <div class="mb-10">
        <div class="flex items-start gap-4 mb-4">
            <span class="flex-shrink-0 w-10 h-10 rounded-full bg-indigo-900/50 flex items-center justify-center text-indigo-400 font-bold text-sm mt-1">6</span>
            <div>
                <h3 class="text-xl font-semibold text-white mb-1">Reciprocal Rank Fusion (RRF) for Hybrid Scoring</h3>
                <p class="text-gray-400 text-sm">Combine keyword search and semantic search using ranks, not raw scores ‚Äî no normalization needed.</p>
            </div>
        </div>
        <div class="bg-card border border-border rounded-lg p-6 ml-14">
            <p class="text-sm text-gray-400 mb-4">
                The naive approach to hybrid search is to normalize BM25 scores (range 0‚Äì15) and cosine similarity scores (range 0‚Äì1) to the same scale and take a weighted average. This is fragile ‚Äî the normalization depends on the query, the corpus size, and the score distributions. RRF sidesteps all of this by operating on <strong class="text-gray-200">ranks</strong> instead of scores.
            </p>
            <div class="bg-gray-900/60 rounded-lg p-4 font-mono text-sm text-indigo-400 mb-4 text-center">
                rrf_score(doc) = 1/(k + rank<sub>bm25</sub>) + 1/(k + rank<sub>vector</sub>)
            </div>
            <div class="space-y-2 text-sm text-gray-400">
                <p>Where <code class="text-indigo-400">k</code> is a constant (default 60, configurable as <code class="text-indigo-400">rrf_k</code>). Three advantages:</p>
                <ul class="list-disc ml-5 space-y-1 text-xs">
                    <li><strong class="text-gray-300">No normalization needed</strong> ‚Äî operates on ranks, not raw scores</li>
                    <li><strong class="text-gray-300">Scale-invariant</strong> ‚Äî BM25 producing scores 0‚Äì15 and cosine producing 0‚Äì1 doesn't matter</li>
                    <li><strong class="text-gray-300">Well-studied</strong> ‚Äî used by Elasticsearch, Vespa, and many production RAG systems</li>
                </ul>
            </div>
            <p class="text-xs text-gray-500 mt-3">
                For keyword-only mode, only BM25 ranks are used. For vector-only, only cosine ranks. For hybrid, both contribute to the final score.
            </p>
        </div>
    </div>

    <!-- Primitive 7: Distraction Detection via Score Disagreement -->
    <div class="mb-10">
        <div class="flex items-start gap-4 mb-4">
            <span class="flex-shrink-0 w-10 h-10 rounded-full bg-red-900/50 flex items-center justify-center text-red-400 font-bold text-sm mt-1">7</span>
            <div>
                <h3 class="text-xl font-semibold text-white mb-1">Distraction Detection via Score Disagreement</h3>
                <p class="text-gray-400 text-sm">A result that ranks high in keywords but low in meaning (or vice versa) is suspicious ‚Äî flag it.</p>
            </div>
        </div>
        <div class="bg-card border border-border rounded-lg p-6 ml-14">
            <p class="text-sm text-gray-400 mb-4">
                Distractors share keywords with the query but mean something different. BM25 ranks them high (keyword overlap), but vector search ranks them low (different semantics). This <strong class="text-gray-200">disagreement between scoring methods</strong> is a detectable signal at query time ‚Äî no golden labels needed.
            </p>
            <div class="bg-gray-900/60 rounded-lg p-4 font-mono text-sm text-red-400 mb-4 text-center">
                disagreement = |rank<sub>bm25</sub> - rank<sub>vector</sub>| / max(rank<sub>bm25</sub>, rank<sub>vector</sub>)
            </div>

            <div class="grid grid-cols-1 md:grid-cols-2 gap-3 mb-4">
                <div class="bg-green-900/10 border border-green-900/20 rounded-lg p-3">
                    <div class="text-xs font-semibold text-green-400 mb-1">Doc A: Consistent ranking</div>
                    <div class="text-xs text-gray-400 font-mono">BM25 rank 2, vector rank 3</div>
                    <div class="text-xs text-gray-400 font-mono">disagreement = 1/3 = <span class="text-green-400">0.33 (OK)</span></div>
                </div>
                <div class="bg-red-900/10 border border-red-900/20 rounded-lg p-3">
                    <div class="text-xs font-semibold text-red-400 mb-1">Doc B: Classic keyword trap</div>
                    <div class="text-xs text-gray-400 font-mono">BM25 rank 1, vector rank 12</div>
                    <div class="text-xs text-gray-400 font-mono">disagreement = 11/12 = <span class="text-red-400">0.92 (FLAGGED)</span></div>
                </div>
            </div>
            <p class="text-xs text-gray-500">
                Doc B matches on keywords but means something different ‚Äî a classic FAQ distractor. The flag appears in query output so the agent can see it, but it does NOT auto-filter the result. The agent decides what to do. At evaluation time (not query time), golden labels provide exact distractor counts as ground truth.
            </p>
        </div>
    </div>

    <!-- Primitive 8: UDCG ‚Äî the core metric -->
    <div class="mb-10">
        <div class="flex items-start gap-4 mb-4">
            <span class="flex-shrink-0 w-10 h-10 rounded-full bg-amber-900/50 flex items-center justify-center text-amber-400 font-bold text-sm mt-1">8</span>
            <div>
                <h3 class="text-xl font-semibold text-white mb-1">UDCG: Utility-Discounted Cumulative Gain</h3>
                <p class="text-gray-400 text-sm">The metric that makes distractors visible ‚Äî traditional nDCG treats wrong answers as harmless zeros. UDCG assigns them -1.</p>
            </div>
        </div>
        <div class="bg-card border border-border rounded-lg p-6 ml-14">
            <div class="bg-gray-900/60 rounded-lg p-4 font-mono text-sm text-amber-400 mb-4 text-center">
                UDCG@k = &Sigma;<sub>i=1</sub><sup>k</sup> utility(doc<sub>i</sub>) / log<sub>2</sub>(i + 1)
            </div>
            <div class="grid grid-cols-3 gap-3 mb-4 max-w-md">
                <div class="bg-green-900/20 border border-green-900/30 rounded-lg p-3 text-center">
                    <div class="text-lg font-bold text-green-400">+1</div>
                    <div class="text-xs text-gray-400">Relevant</div>
                </div>
                <div class="bg-gray-800 border border-gray-700 rounded-lg p-3 text-center">
                    <div class="text-lg font-bold text-gray-500">0</div>
                    <div class="text-xs text-gray-400">Irrelevant</div>
                </div>
                <div class="bg-red-900/20 border border-red-900/30 rounded-lg p-3 text-center">
                    <div class="text-lg font-bold text-red-400">-1</div>
                    <div class="text-xs text-gray-400">Distractor</div>
                </div>
            </div>
            <p class="text-sm text-gray-400 mb-4">
                Each result's contribution is weighted by its rank position ‚Äî a distractor at rank 1 costs more than one at rank 5. The result is normalized by the ideal score (all relevant docs ranked first) to get nUDCG in the range [-1, +1].
            </p>

            <!-- Worked example -->
            <div class="overflow-x-auto mb-4">
                <p class="text-xs font-semibold text-gray-300 mb-2">Worked example ‚Äî query with 3 relevant (R), 1 distractor (D), 1 irrelevant (I):</p>
                <table class="w-full text-xs">
                    <thead>
                        <tr class="text-gray-500 border-b border-border">
                            <th class="text-left py-2 px-3">Rank</th>
                            <th class="text-left py-2 px-3">Doc</th>
                            <th class="text-left py-2 px-3">Utility</th>
                            <th class="text-left py-2 px-3">Discount</th>
                            <th class="text-left py-2 px-3">Contribution</th>
                        </tr>
                    </thead>
                    <tbody class="text-gray-400 font-mono">
                        <tr class="border-b border-border/50"><td class="py-1.5 px-3">1</td><td class="py-1.5 px-3 text-green-400">R</td><td class="py-1.5 px-3">+1.0</td><td class="py-1.5 px-3">1.000</td><td class="py-1.5 px-3 text-green-400">+1.000</td></tr>
                        <tr class="border-b border-border/50 bg-red-900/10"><td class="py-1.5 px-3">2</td><td class="py-1.5 px-3 text-red-400">D</td><td class="py-1.5 px-3">-1.0</td><td class="py-1.5 px-3">0.631</td><td class="py-1.5 px-3 text-red-400">-0.631</td></tr>
                        <tr class="border-b border-border/50"><td class="py-1.5 px-3">3</td><td class="py-1.5 px-3 text-green-400">R</td><td class="py-1.5 px-3">+1.0</td><td class="py-1.5 px-3">0.500</td><td class="py-1.5 px-3 text-green-400">+0.500</td></tr>
                        <tr class="border-b border-border/50"><td class="py-1.5 px-3">4</td><td class="py-1.5 px-3 text-gray-600">I</td><td class="py-1.5 px-3">0.0</td><td class="py-1.5 px-3">0.431</td><td class="py-1.5 px-3 text-gray-600">0.000</td></tr>
                        <tr><td class="py-1.5 px-3">5</td><td class="py-1.5 px-3 text-green-400">R</td><td class="py-1.5 px-3">+1.0</td><td class="py-1.5 px-3">0.387</td><td class="py-1.5 px-3 text-green-400">+0.387</td></tr>
                    </tbody>
                </table>
            </div>
            <div class="grid grid-cols-1 md:grid-cols-3 gap-3 mb-4">
                <div class="bg-gray-900/50 rounded-lg p-3 text-center">
                    <div class="text-xs text-gray-500 mb-1">UDCG@5</div>
                    <div class="text-lg font-bold text-amber-400">1.256</div>
                </div>
                <div class="bg-gray-900/50 rounded-lg p-3 text-center">
                    <div class="text-xs text-gray-500 mb-1">Ideal (3R at top)</div>
                    <div class="text-lg font-bold text-gray-400">2.131</div>
                </div>
                <div class="bg-gray-900/50 rounded-lg p-3 text-center">
                    <div class="text-xs text-gray-500 mb-1">nUDCG@5</div>
                    <div class="text-lg font-bold text-amber-400">0.59</div>
                </div>
            </div>
            <div class="bg-amber-900/15 border border-amber-900/30 rounded-lg p-3 mb-4">
                <p class="text-xs text-amber-400">
                    <strong>Key insight:</strong> The distractor at rank 2 cost 0.631 points. If we removed it and shifted results up, nUDCG would jump to ~0.85. This is what the agent discovers through the feedback loop ‚Äî <strong>removing distractors is more valuable than finding more relevant documents.</strong>
                </p>
            </div>
            <p class="text-xs text-gray-500">
                <strong class="text-gray-400">Document-level dedup:</strong> Golden labels are per-document but retrieval returns per-chunk results. A document may produce multiple chunks. To avoid double-counting: for each document, only the highest-ranked chunk contributes to UDCG. All subsequent chunks from the same document are skipped (utility&nbsp;=&nbsp;0). This prevents distractor penalties from being inflated by multi-chunk documents.
            </p>
        </div>
    </div>

    <!-- Mutually Assured Distraction (MAD) ‚Äî the insight that ties it all together -->
    <div class="mb-10">
        <div class="flex items-start gap-4 mb-4">
            <span class="flex-shrink-0 w-10 h-10 rounded-full bg-rose-900/50 flex items-center justify-center text-rose-400 font-bold text-sm mt-1">!</span>
            <div>
                <h3 class="text-xl font-semibold text-white mb-1">Mutually Assured Distraction (MAD)</h3>
                <p class="text-gray-400 text-sm">The foundational insight: a wrong result doesn't just waste a slot ‚Äî it actively corrupts LLM reasoning.</p>
            </div>
        </div>
        <div class="bg-card border border-border rounded-lg p-6 ml-14">
            <p class="text-sm text-gray-400 mb-4">
                Traditional search evaluation treats results as either relevant (1) or irrelevant (0). This made sense when humans scanned a list ‚Äî an irrelevant result was just skipped. But when an LLM reads search results as context, a <strong class="text-gray-200">distractor</strong> (a result that looks right but is wrong) actively corrupts the answer. The LLM can't distinguish between "API authentication via bearer tokens" and "authentication FAQ about password resets" ‚Äî both mention authentication, but one answers the wrong question.
            </p>
            <p class="text-sm text-gray-400 mb-4">
                This is the MAD insight from Hornet: <strong class="text-gray-200">in LLM-powered retrieval, irrelevant is not the worst outcome ‚Äî misleading is.</strong> An FAQ document about password resets doesn't just fail to help with an API auth question; it pulls the LLM's response toward password reset instructions, contaminating the final answer.
            </p>
            <p class="text-sm text-gray-400">
                Every primitive in Hive exists to address this: UDCG makes the cost visible (-1 per distractor), score disagreement detects them at query time, dynamic-k prevents over-retrieving them, category filters exclude them structurally, and deploy gates prevent configs that increase them. The entire system is oriented around one question: <strong class="text-gray-200">"are we injecting harmful context into the LLM?"</strong>
            </p>
        </div>
    </div>

    <!-- Built from scratch ‚Äî no external search infra -->
    <div class="mb-4">
        <div class="flex items-start gap-4 mb-4">
            <span class="flex-shrink-0 w-10 h-10 rounded-full bg-cyan-900/50 flex items-center justify-center text-cyan-400 font-bold text-sm mt-1">0</span>
            <div>
                <h3 class="text-xl font-semibold text-white mb-1">Zero External Infrastructure</h3>
                <p class="text-gray-400 text-sm">No Elasticsearch. No Pinecone. No Docker. BM25 from scratch, vector search with numpy, all in SQLite.</p>
            </div>
        </div>
        <div class="bg-card border border-border rounded-lg p-6 ml-14">
            <p class="text-sm text-gray-400 mb-4">
                Hive implements the entire search engine from first principles: BM25 scoring with an inverted index (~100 lines), vector search via cosine similarity on numpy arrays, and RRF fusion ‚Äî all stored in a single SQLite database. For the prototype's corpus of ~60 chunks, this runs in milliseconds with no external services.
            </p>
            <div class="grid grid-cols-1 md:grid-cols-2 gap-3 text-xs text-gray-400">
                <div class="bg-gray-900/50 rounded-lg p-3">
                    <strong class="text-cyan-400">BM25</strong>: Inverted index in SQLite. Per-chunk term frequencies in <code>postings</code>, per-term doc frequencies in <code>term_stats</code>, corpus stats for length normalization. O(matching chunks) per query term.
                </div>
                <div class="bg-gray-900/50 rounded-lg p-3">
                    <strong class="text-cyan-400">Vector search</strong>: Embeddings stored as numpy arrays serialized via <code>tobytes()</code> in SQLite BLOBs. Cosine similarity via <code>np.dot</code>. For 50‚Äì150 chunks, this is instant (&lt;5ms). No ANN index needed.
                </div>
                <div class="bg-gray-900/50 rounded-lg p-3">
                    <strong class="text-cyan-400">Pre-filtering</strong>: Category filters applied as a WHERE clause on metadata before scoring. Distractors in excluded categories never enter the ranking pipeline.
                </div>
                <div class="bg-gray-900/50 rounded-lg p-3">
                    <strong class="text-cyan-400">Embedding caching</strong>: Pre-computed embeddings saved to <code>.npz</code> files. Demo runs with cached embeddings ‚Äî no OpenAI API calls during the recording. BM25-only mode available when no API key is set.
                </div>
            </div>
        </div>
    </div>
</section>

<!-- Three-Level Verification -->
<section class="px-6 py-20 max-w-5xl mx-auto">
    <h2 class="text-3xl font-bold text-white mb-4">Three-Level Verification</h2>
    <p class="text-gray-400 mb-10 max-w-2xl">Every config change goes through the same verification pipeline ‚Äî like compiling, linting, and testing code.</p>

    <div class="space-y-4 max-w-2xl">
        <div class="bg-card border border-border rounded-lg p-6">
            <div class="flex items-center gap-3 mb-3">
                <span class="w-8 h-8 rounded-full bg-blue-900/50 flex items-center justify-center text-blue-400">‚úì</span>
                <h3 class="text-lg font-semibold text-white">Syntactic</h3>
                <span class="text-xs text-gray-500 ml-auto">Like a compiler</span>
            </div>
            <p class="text-sm text-gray-400 mb-2">Does the config parse correctly?</p>
            <div class="bg-gray-900/50 rounded px-3 py-2 text-xs font-mono text-gray-500">
                ‚úì top_k is a positive integer &nbsp; ‚úì method is keyword|vector|hybrid &nbsp; ‚úì all required fields present
            </div>
        </div>

        <div class="bg-card border border-border rounded-lg p-6">
            <div class="flex items-center gap-3 mb-3">
                <span class="w-8 h-8 rounded-full bg-purple-900/50 flex items-center justify-center text-purple-400">üß†</span>
                <h3 class="text-lg font-semibold text-white">Semantic</h3>
                <span class="text-xs text-gray-500 ml-auto">Like a linter</span>
            </div>
            <p class="text-sm text-gray-400 mb-2">Do the settings make logical sense together?</p>
            <div class="bg-red-900/20 border border-red-900/30 rounded px-3 py-2 text-xs font-mono text-red-400">
                ‚úó distraction_detection.enabled is true but method is "keyword". Distraction detection requires "hybrid" to compare keyword vs vector rankings.
            </div>
        </div>

        <div class="bg-card border border-border rounded-lg p-6">
            <div class="flex items-center gap-3 mb-3">
                <span class="w-8 h-8 rounded-full bg-green-900/50 flex items-center justify-center text-green-400">üõ°</span>
                <h3 class="text-lg font-semibold text-white">Behavioral</h3>
                <span class="text-xs text-gray-500 ml-auto">Like a test suite</span>
            </div>
            <p class="text-sm text-gray-400 mb-2">Does it actually perform better?</p>
            <div class="bg-red-900/20 border border-red-900/30 rounded px-3 py-2 text-xs font-mono text-red-400">
                Deploy BLOCKED: candidate nUDCG (0.34) &lt; active nUDCG (0.61). The system refuses to make search quality worse.
            </div>
        </div>
    </div>
</section>

<!-- The Demo Story -->
<section class="px-6 py-20 max-w-5xl mx-auto">
    <h2 class="text-3xl font-bold text-white mb-4">The Demo Story</h2>
    <p class="text-gray-400 mb-10 max-w-2xl">An AI agent starts with a naive config and optimizes it in 3 steps ‚Äî zero human intervention.</p>

    <div class="flex flex-col md:flex-row gap-6 mb-8">
        <div class="flex-1 bg-card border border-border rounded-lg p-6">
            <div class="text-xs text-gray-500 mb-2">Act 1</div>
            <h3 class="text-lg font-semibold text-white mb-1">v1: Naive Baseline</h3>
            <p class="text-sm text-gray-400 mb-4">Hybrid search, top-k=10, no filtering, no dynamic-k</p>
            <div class="flex justify-between items-end">
                <div>
                    <div class="text-xs text-gray-500">nUDCG</div>
                    <div class="text-2xl font-bold text-red-400">0.35</div>
                </div>
                <div class="text-right">
                    <div class="text-xs text-gray-500">Distractors</div>
                    <div class="text-2xl font-bold text-red-400">4</div>
                </div>
            </div>
        </div>

        <div class="flex-1 bg-card border border-border rounded-lg p-6">
            <div class="text-xs text-gray-500 mb-2">Act 2</div>
            <h3 class="text-lg font-semibold text-white mb-1">v2: Filter + Detect</h3>
            <p class="text-sm text-gray-400 mb-4">Agent excludes FAQ category, enables distraction detection</p>
            <div class="flex justify-between items-end">
                <div>
                    <div class="text-xs text-gray-500">nUDCG</div>
                    <div class="text-2xl font-bold text-yellow-400">0.58</div>
                </div>
                <div class="text-right">
                    <div class="text-xs text-gray-500">Distractors</div>
                    <div class="text-2xl font-bold text-yellow-400">1</div>
                </div>
            </div>
        </div>

        <div class="flex-1 bg-card border border-border rounded-lg p-6">
            <div class="text-xs text-gray-500 mb-2">Act 3</div>
            <h3 class="text-lg font-semibold text-white mb-1">v3: Dynamic-k</h3>
            <p class="text-sm text-gray-400 mb-4">Agent enables gap-based cutoff ‚Äî fewer results, higher quality</p>
            <div class="flex justify-between items-end">
                <div>
                    <div class="text-xs text-gray-500">nUDCG</div>
                    <div class="text-2xl font-bold text-green-400">0.75</div>
                </div>
                <div class="text-right">
                    <div class="text-xs text-gray-500">Distractors</div>
                    <div class="text-2xl font-bold text-green-400">0</div>
                </div>
            </div>
        </div>
    </div>

    <div class="bg-green-900/20 border border-green-700/40 rounded-lg p-4 max-w-2xl">
        <p class="text-green-400 font-semibold">
            Result: nUDCG improved 114% (0.35 ‚Üí 0.75). Distractors eliminated (4 ‚Üí 0). Zero human intervention.
        </p>
    </div>
</section>

<!-- Architecture -->
<section class="px-6 py-20 max-w-5xl mx-auto">
    <h2 class="text-3xl font-bold text-white mb-4">How It Works</h2>
    <p class="text-gray-400 mb-10 max-w-2xl">Everything runs locally. SQLite for storage, Python for the engine, JSON files for configs.</p>

    <div class="bg-card border border-border rounded-lg p-8 overflow-x-auto">
        <pre class="mermaid">
flowchart TD
    subgraph workspace [Workspace: Files on Disk]
        Collections["collections/*.json"]
        Configs["configs/*.json"]
        ActiveConfig["configs/active.json"]
        Documents["documents/*.md"]
        Evals["evals/golden.json"]
    end

    subgraph engine [Hive Engine]
        Validator["Validator\n(syntactic + semantic + behavioral)"]
        Indexer["Indexer\n(chunk + BM25 + embed)"]
        Searcher["Searcher\n(RRF + dynamic-k + disagreement)"]
        Evaluator["Evaluator\n(UDCG + comparison)"]
    end

    subgraph storage [SQLite: hive.db]
        ChunksTable["chunks"]
        PostingsTable["postings + term_stats"]
        ConfigHistory["config_versions"]
        EvalResults["eval_results"]
    end

    CLI["CLI: validate | index | query | evaluate | compare | deploy"]

    CLI --> Validator
    CLI --> Indexer
    CLI --> Searcher
    CLI --> Evaluator

    Validator --> Configs
    Indexer --> Documents
    Searcher --> ChunksTable
    Evaluator --> Evals
        </pre>
    </div>
</section>

<!-- Key Concepts -->
<section class="px-6 py-20 max-w-5xl mx-auto">
    <h2 class="text-3xl font-bold text-white mb-4">Key Concepts</h2>
    <p class="text-gray-400 mb-10 max-w-2xl">Quick reference for non-technical readers.</p>

    <div class="grid grid-cols-1 md:grid-cols-2 gap-4 max-w-3xl">
        <div class="bg-card border border-border rounded-lg p-5">
            <h3 class="font-semibold text-white mb-2">UDCG</h3>
            <p class="text-sm text-gray-400">A search quality score that <strong class="text-gray-300">penalizes wrong answers</strong>, not just rewards right ones. Traditional nDCG treats distractors as harmless zeros.</p>
        </div>
        <div class="bg-card border border-border rounded-lg p-5">
            <h3 class="font-semibold text-white mb-2">Distractor</h3>
            <p class="text-sm text-gray-400">A search result that <strong class="text-gray-300">looks right but means something different</strong>. Like finding "Password Reset FAQ" when you searched for "API Authentication."</p>
        </div>
        <div class="bg-card border border-border rounded-lg p-5">
            <h3 class="font-semibold text-white mb-2">Dynamic-k</h3>
            <p class="text-sm text-gray-400">Instead of always returning 10 results, <strong class="text-gray-300">stop when quality drops off a cliff</strong>. Fewer results = fewer chances for distractors to sneak in.</p>
        </div>
        <div class="bg-card border border-border rounded-lg p-5">
            <h3 class="font-semibold text-white mb-2">RRF (Reciprocal Rank Fusion)</h3>
            <p class="text-sm text-gray-400">A way to <strong class="text-gray-300">combine keyword search and meaning search</strong> without worrying about incompatible score scales. Rank-based, not score-based.</p>
        </div>
        <div class="bg-card border border-border rounded-lg p-5">
            <h3 class="font-semibold text-white mb-2">Deploy Gate</h3>
            <p class="text-sm text-gray-400">The system <strong class="text-gray-300">refuses to deploy a config that makes search quality worse</strong>. Like a CI pipeline that blocks merging if tests fail.</p>
        </div>
        <div class="bg-card border border-border rounded-lg p-5">
            <h3 class="font-semibold text-white mb-2">Feedback Loop</h3>
            <p class="text-sm text-gray-400">The agent <strong class="text-gray-300">tries, measures, learns, and tries again</strong>. Like a developer running tests after each code change ‚Äî but fully automated.</p>
        </div>
    </div>
</section>

<!-- Footer -->
<footer class="px-6 py-12 text-center text-gray-600 text-sm border-t border-border">
    <p>Hive ‚Äî An OSS Retrieval Engine with Verifiable Feedback Loops</p>
    <p class="mt-2">
        <a href="https://github.com" class="text-blue-400 hover:underline">GitHub</a> ¬∑
        Built with SQLite, Python, and first-principles thinking
    </p>
</footer>

<script>
    mermaid.initialize({
        startOnLoad: true,
        theme: 'dark',
        themeVariables: {
            primaryColor: '#1e293b',
            primaryBorderColor: '#334155',
            lineColor: '#64748b',
            textColor: '#e2e8f0',
        }
    });

    function toggleDetail(id) {
        const el = document.getElementById(id);
        el.classList.toggle('open');
    }

    // Trigger progress bar animation on scroll
    const observer = new IntersectionObserver((entries) => {
        entries.forEach(entry => {
            if (entry.isIntersecting) {
                entry.target.querySelector('.animate-fill').style.animationPlayState = 'running';
            }
        });
    }, { threshold: 0.5 });

    const bar = document.getElementById('progress-bar-container');
    if (bar) {
        const fill = bar.querySelector('.animate-fill');
        fill.style.animationPlayState = 'paused';
        observer.observe(bar);
    }
</script>

</body>
</html>
